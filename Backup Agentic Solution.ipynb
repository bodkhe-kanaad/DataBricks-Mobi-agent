{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3274a348-2217-4fd9-9763-bec810e618b9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "COMMENT ON COLUMN `vanhack`.`mobi_data`.`silver_stations`.`station_id` IS 'Unique identifier for the station id record.'\n",
      "COMMENT ON COLUMN `vanhack`.`mobi_data`.`silver_stations`.`name` IS 'Name value stored as string.'\n",
      "COMMENT ON COLUMN `vanhack`.`mobi_data`.`silver_stations`.`lat` IS 'Lat value stored as double.'\n",
      "COMMENT ON COLUMN `vanhack`.`mobi_data`.`silver_stations`.`lon` IS 'Lon value stored as double.'\n",
      "COMMENT ON COLUMN `vanhack`.`mobi_data`.`silver_stations`.`is_virtual_station` IS 'Is virtual station value stored as boolean.'\n",
      "COMMENT ON COLUMN `vanhack`.`mobi_data`.`silver_stations`.`capacity` IS 'Capacity value stored as bigint.'\n",
      "COMMENT ON COLUMN `vanhack`.`mobi_data`.`silver_stations`.`vehicle_type_capacity` IS 'Vehicle type capacity value stored as struct<1:bigint,2:bigint,3:bigint>.'\n",
      "COMMENT ON COLUMN `vanhack`.`mobi_data`.`silver_stations`.`is_valet_station` IS 'Is valet station value stored as boolean.'\n",
      "COMMENT ON COLUMN `vanhack`.`mobi_data`.`silver_stations`.`is_charging_station` IS 'Is charging station value stored as boolean.'\n",
      "COMMENT ON COLUMN `vanhack`.`mobi_data`.`silver_stations`.`rental_uris` IS 'Rental uris value stored as struct<android:string,ios:string>.'\n",
      "COMMENT ON COLUMN `vanhack`.`mobi_data`.`silver_stations`.`data_fetched_at` IS 'Data fetched at value stored as timestamp_ntz.'\n",
      "COMMENT ON COLUMN `vanhack`.`mobi_data`.`silver_stations`.`num_bikes_available` IS 'Num bikes available value stored as bigint.'\n",
      "COMMENT ON COLUMN `vanhack`.`mobi_data`.`silver_stations`.`num_docks_available` IS 'Num docks available value stored as bigint.'\n",
      "COMMENT ON COLUMN `vanhack`.`mobi_data`.`silver_stations`.`is_installed` IS 'Is installed value stored as boolean.'\n",
      "COMMENT ON COLUMN `vanhack`.`mobi_data`.`silver_stations`.`is_renting` IS 'Is renting value stored as boolean.'\n",
      "COMMENT ON COLUMN `vanhack`.`mobi_data`.`silver_stations`.`is_returning` IS 'Is returning value stored as boolean.'\n",
      "COMMENT ON COLUMN `vanhack`.`mobi_data`.`silver_stations`.`last_reported` IS 'Last reported value stored as bigint.'\n",
      "COMMENT ON COLUMN `vanhack`.`mobi_data`.`silver_stations`.`vehicle_types_available` IS 'Vehicle types available value stored as array<struct<count:bigint,vehicle_type_id:string>>.'\n",
      "COMMENT ON COLUMN `vanhack`.`mobi_data`.`silver_stations`.`status_fetched_at` IS 'Status fetched at value stored as timestamp_ntz.'\n",
      "COMMENT ON COLUMN `vanhack`.`mobi_data`.`silver_stations`.`station_name` IS 'Station name value stored as string.'\n",
      "COMMENT ON COLUMN `vanhack`.`mobi_data`.`silver_stations`.`station_key` IS 'Station key value stored as string.'\n",
      "COMMENT ON COLUMN `vanhack`.`mobi_data`.`silver_stations`.`station_pk` IS 'Station pk value stored as string.'\n",
      "=== METADATA UPDATE RESULT ===\n",
      "‚ÑπÔ∏è Generated placeholder comment for `station_id` ‚Üí Unique identifier for the station id record.\n",
      "üîπ Updated column `station_id` ‚Üí Unique identifier for the station id record.\n",
      "‚ÑπÔ∏è Generated placeholder comment for `name` ‚Üí Name value stored as string.\n",
      "üîπ Updated column `name` ‚Üí Name value stored as string.\n",
      "‚ÑπÔ∏è Generated placeholder comment for `lat` ‚Üí Lat value stored as double.\n",
      "üîπ Updated column `lat` ‚Üí Lat value stored as double.\n",
      "‚ÑπÔ∏è Generated placeholder comment for `lon` ‚Üí Lon value stored as double.\n",
      "üîπ Updated column `lon` ‚Üí Lon value stored as double.\n",
      "‚ÑπÔ∏è Generated placeholder comment for `is_virtual_station` ‚Üí Is virtual station value stored as boolean.\n",
      "üîπ Updated column `is_virtual_station` ‚Üí Is virtual station value stored as boolean.\n",
      "‚ÑπÔ∏è Generated placeholder comment for `capacity` ‚Üí Capacity value stored as bigint.\n",
      "üîπ Updated column `capacity` ‚Üí Capacity value stored as bigint.\n",
      "‚ÑπÔ∏è Generated placeholder comment for `vehicle_type_capacity` ‚Üí Vehicle type capacity value stored as struct<1:bigint,2:bigint,3:bigint>.\n",
      "üîπ Updated column `vehicle_type_capacity` ‚Üí Vehicle type capacity value stored as struct<1:bigint,2:bigint,3:bigint>.\n",
      "‚ÑπÔ∏è Generated placeholder comment for `is_valet_station` ‚Üí Is valet station value stored as boolean.\n",
      "üîπ Updated column `is_valet_station` ‚Üí Is valet station value stored as boolean.\n",
      "‚ÑπÔ∏è Generated placeholder comment for `is_charging_station` ‚Üí Is charging station value stored as boolean.\n",
      "üîπ Updated column `is_charging_station` ‚Üí Is charging station value stored as boolean.\n",
      "‚ÑπÔ∏è Generated placeholder comment for `rental_uris` ‚Üí Rental uris value stored as struct<android:string,ios:string>.\n",
      "üîπ Updated column `rental_uris` ‚Üí Rental uris value stored as struct<android:string,ios:string>.\n",
      "‚ÑπÔ∏è Generated placeholder comment for `data_fetched_at` ‚Üí Data fetched at value stored as timestamp_ntz.\n",
      "üîπ Updated column `data_fetched_at` ‚Üí Data fetched at value stored as timestamp_ntz.\n",
      "‚ÑπÔ∏è Generated placeholder comment for `num_bikes_available` ‚Üí Num bikes available value stored as bigint.\n",
      "üîπ Updated column `num_bikes_available` ‚Üí Num bikes available value stored as bigint.\n",
      "‚ÑπÔ∏è Generated placeholder comment for `num_docks_available` ‚Üí Num docks available value stored as bigint.\n",
      "üîπ Updated column `num_docks_available` ‚Üí Num docks available value stored as bigint.\n",
      "‚ÑπÔ∏è Generated placeholder comment for `is_installed` ‚Üí Is installed value stored as boolean.\n",
      "üîπ Updated column `is_installed` ‚Üí Is installed value stored as boolean.\n",
      "‚ÑπÔ∏è Generated placeholder comment for `is_renting` ‚Üí Is renting value stored as boolean.\n",
      "üîπ Updated column `is_renting` ‚Üí Is renting value stored as boolean.\n",
      "‚ÑπÔ∏è Generated placeholder comment for `is_returning` ‚Üí Is returning value stored as boolean.\n",
      "üîπ Updated column `is_returning` ‚Üí Is returning value stored as boolean.\n",
      "‚ÑπÔ∏è Generated placeholder comment for `last_reported` ‚Üí Last reported value stored as bigint.\n",
      "üîπ Updated column `last_reported` ‚Üí Last reported value stored as bigint.\n",
      "‚ÑπÔ∏è Generated placeholder comment for `vehicle_types_available` ‚Üí Vehicle types available value stored as array<struct<count:bigint,vehicle_type_id:string>>.\n",
      "üîπ Updated column `vehicle_types_available` ‚Üí Vehicle types available value stored as array<struct<count:bigint,vehicle_type_id:string>>.\n",
      "‚ÑπÔ∏è Generated placeholder comment for `status_fetched_at` ‚Üí Status fetched at value stored as timestamp_ntz.\n",
      "üîπ Updated column `status_fetched_at` ‚Üí Status fetched at value stored as timestamp_ntz.\n",
      "‚ÑπÔ∏è Generated placeholder comment for `station_name` ‚Üí Station name value stored as string.\n",
      "üîπ Updated column `station_name` ‚Üí Station name value stored as string.\n",
      "‚ÑπÔ∏è Generated placeholder comment for `station_key` ‚Üí Station key value stored as string.\n",
      "üîπ Updated column `station_key` ‚Üí Station key value stored as string.\n",
      "‚ÑπÔ∏è Generated placeholder comment for `station_pk` ‚Üí Station pk value stored as string.\n",
      "üîπ Updated column `station_pk` ‚Üí Station pk value stored as string.\n"
     ]
    }
   ],
   "source": [
    "# Databricks notebook source\n",
    "%pip install langchain-core langchain-openai langchain-community pyyaml\n",
    "\n",
    "# COMMAND ----------\n",
    "\n",
    "open_ai_key = \"\"\n",
    "\n",
    "table_address_default = \"vanhack.mobi_data.silver_stations\"\n",
    "data_contract_default_path = \"/Workspace/Users/jazz@jazzgrewal.com/mobi_agent_starter/datacontract.yml\"\n",
    "\n",
    "# Create widgets\n",
    "dbutils.widgets.text(\"table_address\", table_address_default)\n",
    "dbutils.widgets.text(\"data_contract_path\", data_contract_default_path)\n",
    "\n",
    "# Read widget values\n",
    "table_address = dbutils.widgets.get(\"table_address\")\n",
    "data_contract_path = dbutils.widgets.get(\"data_contract_path\")\n",
    "\n",
    "# COMMAND ----------\n",
    "\n",
    "# ------------------------------------------------------\n",
    "# 0. SETUP: Load OpenAI key from Databricks Secrets\n",
    "# ------------------------------------------------------\n",
    "open_ai_key = open_ai_key #dbutils.secrets.get(\"openai\", \"api_key\")\n",
    "\n",
    "from openai import OpenAI\n",
    "import json\n",
    "import yaml\n",
    "import re\n",
    "\n",
    "\n",
    "def read_contract(file_path: str) -> dict:\n",
    "    \"\"\"Load a YAML data contract from disk.\"\"\"\n",
    "    try:\n",
    "        with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "            content = f.read()\n",
    "    except FileNotFoundError as exc:\n",
    "        raise FileNotFoundError(\n",
    "            f\"Data contract file not found at `{file_path}`.\"\n",
    "        ) from exc\n",
    "\n",
    "    contract = yaml.safe_load(content) or {}\n",
    "    if not isinstance(contract, dict):\n",
    "        raise ValueError(\"Data contract must deserialize to a dictionary.\")\n",
    "\n",
    "    return contract\n",
    "\n",
    "\n",
    "def extract_column_descriptions(contract: dict) -> dict:\n",
    "    \"\"\"Recursively collect column descriptions from a data contract.\"\"\"\n",
    "\n",
    "    descriptions = {}\n",
    "\n",
    "    def _extract_from_columns(columns_obj):\n",
    "        if not isinstance(columns_obj, dict):\n",
    "            return\n",
    "        for column_name, payload in columns_obj.items():\n",
    "            if isinstance(payload, dict):\n",
    "                description = payload.get(\"description\") or payload.get(\"comment\")\n",
    "                if isinstance(description, str) and description.strip():\n",
    "                    descriptions[str(column_name)] = description.strip()\n",
    "            elif isinstance(payload, str) and payload.strip():\n",
    "                descriptions[str(column_name)] = payload.strip()\n",
    "\n",
    "    def _walk(node):\n",
    "        if isinstance(node, dict):\n",
    "            for key, value in node.items():\n",
    "                if key.lower() == \"columns\":\n",
    "                    _extract_from_columns(value)\n",
    "                else:\n",
    "                    _walk(value)\n",
    "        elif isinstance(node, list):\n",
    "            for item in node:\n",
    "                _walk(item)\n",
    "\n",
    "    _walk(contract)\n",
    "    return descriptions\n",
    "\n",
    "\n",
    "def generate_placeholder_description(column_name: str, data_type: str) -> str:\n",
    "    \"\"\"Produce a human-style one-line fallback description.\"\"\"\n",
    "\n",
    "    words = column_name.replace(\"_\", \" \")\n",
    "    words = re.sub(r\"\\s+\", \" \", words).strip()\n",
    "    if not words:\n",
    "        words = column_name\n",
    "\n",
    "    # Simple heuristic for ID fields\n",
    "    if re.search(r\"id$\", column_name, re.IGNORECASE):\n",
    "        return f\"Unique identifier for the {words.lower()} record.\".capitalize()\n",
    "\n",
    "    return f\"{words.capitalize()} value stored as {data_type}.\"\n",
    "\n",
    "client = OpenAI(api_key=open_ai_key)\n",
    "\n",
    "data_contract = read_contract(data_contract_path)\n",
    "baseline_contract_columns = extract_column_descriptions(data_contract)\n",
    "\n",
    "# data_contract_json = json.dumps(data_contract, indent=2)\n",
    "data_contract_json = json.dumps(data_contract, indent=2, default=str)\n",
    "contract_column_guidance_json = json.dumps(baseline_contract_columns, indent=2, default=str)\n",
    "# contract_column_guidance_json = json.dumps(baseline_contract_columns, indent=2)\n",
    "\n",
    "def escape_table_address(table_address: str):\n",
    "    parts = table_address.split(\".\")\n",
    "    if len(parts) != 3:\n",
    "        raise ValueError(f\"Invalid UC table address: {table_address}\")\n",
    "\n",
    "    catalog, schema, table = parts\n",
    "    return f\"`{catalog}`.`{schema}`.`{table}`\"\n",
    "\n",
    "\n",
    "def escape_identifier(identifier: str) -> str:\n",
    "    \"\"\"Backtick-escape Unity Catalog identifiers.\"\"\"\n",
    "    if \"`\" in identifier:\n",
    "        raise ValueError(f\"Identifier contains illegal backtick: {identifier}\")\n",
    "    return f\"`{identifier}`\"\n",
    "\n",
    "\n",
    "def sql_escape_literal(value: str) -> str:\n",
    "    \"\"\"Escape single quotes for safe SQL literal usage.\"\"\"\n",
    "    return value.replace(\"'\", \"''\")\n",
    "\n",
    "\n",
    "# ======================================================\n",
    "# 1. METADATA UPDATER TOOL ‚Äî REAL UNITY CATALOG UPDATES\n",
    "# ======================================================\n",
    "def metadata_creator(table_address: str, data_contract: dict):\n",
    "    \"\"\"\n",
    "    Updates Unity Catalog table & column comments based on a data contract.\n",
    "\n",
    "    Example contract:\n",
    "    {\n",
    "        \"table_comment\": \"Table description\",\n",
    "        \"columns\": {\n",
    "            \"col1\": \"Comment1\",\n",
    "            \"col2\": \"Comment2\"\n",
    "        }\n",
    "    }\n",
    "    \"\"\"\n",
    "\n",
    "    summary = []\n",
    "    \n",
    "    # --------------------------------------------------\n",
    "    # Validate table exists\n",
    "    # --------------------------------------------------\n",
    "    try:\n",
    "        table = spark.table(table_address)\n",
    "    except Exception as e:\n",
    "        return f\"‚ùå Table not found: {table_address}\\n{str(e)}\"\n",
    "\n",
    "    schema_fields = {field.name: field for field in table.schema.fields}\n",
    "    schema_cols = list(schema_fields.keys())\n",
    "    escaped_table_address = escape_table_address(table_address)\n",
    "\n",
    "\n",
    "    # --------------------------------------------------\n",
    "    # 1. Update table comment\n",
    "    # --------------------------------------------------\n",
    "    if \"table_comment\" in data_contract and data_contract[\"table_comment\"]:\n",
    "        comment = str(data_contract[\"table_comment\"]).strip()\n",
    "        sql = f\"COMMENT ON TABLE {escaped_table_address} IS '{sql_escape_literal(comment)}'\"\n",
    "        print(sql)\n",
    "        spark.sql(sql)\n",
    "        summary.append(f\"‚úÖ Updated table comment ‚Üí {comment}\")\n",
    "\n",
    "\n",
    "    # --------------------------------------------------\n",
    "    # 2. Update column-level comments\n",
    "    # --------------------------------------------------\n",
    "    columns_payload = {}\n",
    "    if \"columns\" in data_contract and isinstance(data_contract[\"columns\"], dict):\n",
    "        columns_payload = {k: v for k, v in data_contract[\"columns\"].items() if isinstance(k, str)}\n",
    "\n",
    "    unknown_columns = sorted(set(columns_payload.keys()) - set(schema_cols))\n",
    "    if unknown_columns:\n",
    "        summary.append(\n",
    "            \"‚ö†Ô∏è Ignored unknown columns \" + \", \".join(f\"`{col}`\" for col in unknown_columns)\n",
    "        )\n",
    "\n",
    "    for col in schema_cols:\n",
    "        field = schema_fields[col]\n",
    "        base_comment = columns_payload.get(col)\n",
    "        comment_text = str(base_comment).strip() if base_comment is not None else \"\"\n",
    "\n",
    "        if not comment_text:\n",
    "            baseline_comment = baseline_contract_columns.get(col)\n",
    "            if baseline_comment:\n",
    "                comment_text = baseline_comment.strip()\n",
    "                summary.append(f\"‚ÑπÔ∏è Reused baseline contract comment for `{col}` ‚Üí {comment_text}\")\n",
    "            else:\n",
    "                comment_text = generate_placeholder_description(col, field.dataType.simpleString())\n",
    "                summary.append(f\"‚ÑπÔ∏è Generated placeholder comment for `{col}` ‚Üí {comment_text}\")\n",
    "\n",
    "        column_ref = f\"{escaped_table_address}.{escape_identifier(col)}\"\n",
    "        sql = f\"COMMENT ON COLUMN {column_ref} IS '{sql_escape_literal(comment_text)}'\"\n",
    "        print(sql)\n",
    "        spark.sql(sql)\n",
    "        summary.append(f\"üîπ Updated column `{col}` ‚Üí {comment_text}\")\n",
    "\n",
    "\n",
    "    # --------------------------------------------------\n",
    "    # 3. Done\n",
    "    # --------------------------------------------------\n",
    "    return \"\\n\".join(summary)\n",
    "\n",
    "\n",
    "# ------------------------------------------------------\n",
    "# Build schema overview for prompt engineering context\n",
    "# ------------------------------------------------------\n",
    "try:\n",
    "    table = spark.table(table_address)\n",
    "except Exception as exc:\n",
    "    raise RuntimeError(\n",
    "        f\"Unable to load table `{table_address}` to build schema overview.\"\n",
    "    ) from exc\n",
    "\n",
    "schema_overview = []\n",
    "for field in table.schema.fields:\n",
    "    comment = \"\"\n",
    "    if field.metadata and \"comment\" in field.metadata:\n",
    "        comment = field.metadata[\"comment\"]\n",
    "    schema_overview.append(\n",
    "        {\n",
    "            \"name\": field.name,\n",
    "            \"type\": field.dataType.simpleString(),\n",
    "            \"nullable\": field.nullable,\n",
    "            \"existing_comment\": comment,\n",
    "        }\n",
    "    )\n",
    "\n",
    "schema_overview_json = json.dumps(schema_overview, indent=2)\n",
    "\n",
    "\n",
    "# ======================================================\n",
    "# 2. TOOL SCHEMA FOR OPENAI FUNCTION CALLING\n",
    "# ======================================================\n",
    "tools = [\n",
    "    {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "            \"name\": \"metadata_creator\",\n",
    "            \"description\": \"Applies Unity Catalog table and column comments using the provided data contract.\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"additionalProperties\": False,\n",
    "                \"properties\": {\n",
    "                    \"table_address\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"description\": \"Unity Catalog table address in the form catalog.schema.table.\"\n",
    "                    },\n",
    "                    \"data_contract\": {\n",
    "                        \"type\": \"object\",\n",
    "                        \"additionalProperties\": False,\n",
    "                        \"properties\": {\n",
    "                            \"table_comment\": {\n",
    "                                \"type\": \"string\",\n",
    "                                \"description\": \"Optional table-level description\"\n",
    "                            },\n",
    "                            \"columns\": {\n",
    "                                \"type\": \"object\",\n",
    "                                \"description\": \"Mapping of column name to desired comment.\",\n",
    "                                \"minProperties\": 1,\n",
    "                                \"additionalProperties\": {\"type\": \"string\"}\n",
    "                            }\n",
    "                        },\n",
    "                        \"required\": [\"columns\"]\n",
    "                    }\n",
    "                },\n",
    "                \"required\": [\"table_address\", \"data_contract\"]\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "]\n",
    "\n",
    "\n",
    "\n",
    "# ======================================================\n",
    "# 3. CALL THE AGENT\n",
    "# ======================================================\n",
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": (\n",
    "                \"You are a meticulous Data Governance Agent working in Databricks. \"\n",
    "                \"Generate column-level Unity Catalog metadata updates. \"\n",
    "                \"Always reply by calling the provided tool with valid JSON arguments, \"\n",
    "                \"include every column exactly once, and avoid hallucinating new columns.\"\n",
    "            )\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": f\"\"\"\n",
    "Please craft concise, high-quality descriptions for every column in the Unity Catalog table \"{table_address}\".\n",
    "\n",
    "Table schema (JSON):\n",
    "{schema_overview_json}\n",
    "\n",
    "Data contract (YAML ‚Üí JSON):\n",
    "{data_contract_json}\n",
    "\n",
    "Column guidance extracted from contract:\n",
    "{contract_column_guidance_json}\n",
    "\n",
    "Requirements:\n",
    "- Respond by invoking the `metadata_creator` tool only.\n",
    "- `data_contract.columns` must include all columns listed above with helpful descriptions.\n",
    "- Reuse or refine `existing_comment` and data contract guidance when informative; otherwise write a new, human-friendly, one-sentence description that clarifies the column's business meaning.\n",
    "- Omit `table_comment` unless you have a strong justification.\n",
    "- Do not add or remove columns, and do not include commentary outside the tool call.\n",
    "            \"\"\"\n",
    "        }\n",
    "    ],\n",
    "    tools=tools,\n",
    "    tool_choice=\"auto\"\n",
    ")\n",
    "\n",
    "msg = response.choices[0].message\n",
    "\n",
    "\n",
    "\n",
    "# ======================================================\n",
    "# 4. HANDLE TOOL CALL (Execute Python function)\n",
    "# ======================================================\n",
    "if msg.tool_calls:\n",
    "    for call in msg.tool_calls:\n",
    "        name = call.function.name\n",
    "        args = json.loads(call.function.arguments)\n",
    "\n",
    "        if name == \"metadata_creator\":\n",
    "            result = metadata_creator(**args)\n",
    "            print(\"=== METADATA UPDATE RESULT ===\")\n",
    "            print(result)\n",
    "\n",
    "else:\n",
    "    print(\"LLM response (no tool call):\")\n",
    "    print(msg.content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "57b54599-3d73-4f50-88a4-bd20bf49e20d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 7346049628470433,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "data_governance_agent_backup",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
